\chapter{Future Scope and Conclusion}
\label{chap:conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%   SECTION   %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Scope}
There are lot of space for fine tuning the application and extending this research work. Some of them are discussed below.

\subsection{Parallel Executable Modules}
Latency reduction is greatly influenced by the amount of parallelism available in the application. Among the A/A mode benchmarks, Convolution and FFT are the major latency contributors. Scheme-3 executes FFT for every channel (Sum, Guard, Azimuth and Elevation) in sequential order, whilst Scheme-4 performs channel computations in parallel. In any case, single instance of FFT library is executed in serial. Breaking the FFT and Convolution functional block into parallel executable modules will allow greater improvement of execution time. This enables more than one core performing FFT computation of one channel, resulting in speed-up factor of broken parallel modules. \vspace*{0.2cm}

Functional blocks like Complex Multiply Accumulate (CMYACC), Range Multiply (RMY), Magnitude (MAG), Area Average Calculation (AVG) and Comparison (CMPR) have high level of parallelism. Loop iterations in the above functional blocks can be split to run in parallel. Effective speed-up will be equal to number of parallel executable modules. Although breaking the application for parallel execution increases speed-up, it needs more computing entities to carry out the task and new scheduling schemes. This is a starting point of the optimization and requires further feasibility study.

\subsection{Architectural Features}
The \verb|FFTW| library might not have used special architecture features, since regardless of turning on the \verb|arm| specific compiler switches, it complained 
\begin{compactitem}
	\item[] \verb|not vectorized: not enough data-refs in basic block.|
	\item[] \verb|not vectorized: failed to find SLP opportunities in basic block.|
\end{compactitem}
So it is not optimized for ARM Cortex A9 platform. 128-bit advanced SIMD unit of the ARM Cortex A9 processor can perform four math operations of 32-bit data at the cost of one math operation. Exploiting such feature will reduce the latency of the computation heavy modules in single threaded as well as multi-threaded environment.

\subsection{Cache Performance}
The more the cache hit rate, the less the memory transfer between SDRAM and core. Fetching data from memory is relatively slow and expensive. Corner turning is implemented as generic row-column transpose form. The data access pattern row-column wise, makes frequent cache misses. Corner turning can be implemented by Cache-Oblivious Algorithm as explained in \textsl{Cache Oblivious Matrix Transposition:Simulation and Experiment} \cite{cot}, to improve data locality. This will reduce memory transfer bandwidth as well as execution time.  \vspace*{0.2cm}

In Scheme-5, the burst data size after beam-forming is 52KiB. A core having 32KiB private L1 cache can hold up to 61\% of the beamformed data. As an over approximation approach, 0\% cache hit rate is assumed for the analysis. This is not the case in real world. Cache hit rate prediction mechanism shall be employed to have more realistic results. \vspace*{0.2cm}

Effect of various L2-Cache size and Memory size can be performed to determine the optimal size for working set data. Another interesting cache profiling is \textsl{cache data utilization ratio}, it is the ratio of the amount of data fetched from memory to the amount of data used by the CPU before the data is evicted. Such measurements in L1 cache and L2 cache indicate whether changes in the algorithm will yield significant reduction in execution time.

\subsection{A/G Mode}
This thesis has only considered A/A Mode processing of the Radar processor. The techniques shall be extended to adopt A/G Mode processing. A Radar processor should be capable of performing A/A Mode and A/G Mode processing in real time.

%\clearpage
\section{Conclusion}
\label{sec:ch5:conclustion}
This thesis has presented the Airborne Radar processing chain on IMA processor architecture for safety critical systems and baseline  analysis. Inference from the baseline analysis is that the latency is far higher than the acceptable values. Data dependency is scrutinized to leverage parallelism in the application. Pseudo algorithm of the Radar processing chain is implemented and the latency is measured on a real hardware. Measurement tools for memory utilization and bandwidth utilization have been made. \vspace*{0.2cm}

Couple of optimization schemes have been implemented for Air to Air Mode processing. Based on the new scheduling schemes, the optimized scheme(Scheme-4) guarantees 7.5x speed-up than the baseline analysis with lesser number of resources. The achieved 2x Dwell time latency is healthy enough for the A/A Mode Radar processor. \vspace*{0.2cm}

This thesis concludes that the simplified A/A mode Radar processing can be done on the IMA processor architecture in real time. It saves space, weight and power requirements. To compare this in day to day life, eight Samsung Galaxy S-III mobiles are sufficient to deliver 2x Dwell time latency with 87\% CPU utilization!
